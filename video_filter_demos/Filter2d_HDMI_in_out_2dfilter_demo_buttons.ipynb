{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# 2D Filter demo\n",
    "\n",
    "## Requirements\n",
    "\n",
    "Custom video overlay for Pynq-Z1 v2.0 image\n",
    "HDMI In 1280x720 (720p) source connected to the board\n",
    "\n",
    "This demo allows the pushbuttons on the board to be used to select different filters. \n",
    "## Slideshow\n",
    "\n",
    "* If the resolution is incorrectly set the first time the board is connected, set the resolution, and rerun all the cells in this notebook\n",
    " \n",
    "This demo is intended to be run as a slideshow. \n",
    "\n",
    "Go to View > Cell Toolbar > Slideshow to see the *Slideshow options* for each cell. From here you can select which slides will be included or excluded from the presentation. \n",
    "\n",
    "Code cells can be executed from the slideshow view by clicking the code cell, and pressing CTRL + ENTER\n",
    "\n",
    "\n",
    "## Instructions to run the demo:\n",
    "\n",
    "* Before entering the slideshow view, click Cell > Run All to execute all the code in the notebook. \n",
    "\n",
    "In slideshow mode, use the cursor keys (left right) to navigate through the presentation\n",
    "\n",
    "* Press Alt + r to enter the slideshow and hide this view. (Exit slideshow mode with the same keys Alt + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pynq.overlays.base import BaseOverlay\n",
    "base = BaseOverlay(\"./filter.bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x2f44ba30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pynq.lib.video import *\n",
    "rgba = PixelFormat(32, COLOR_IN_RGB, COLOR_OUT_RGB)\n",
    "mode = VideoMode(1280, 720, 32)\n",
    "\n",
    "base.video.hdmi_in.configure(rgba)\n",
    "\n",
    "base.video.hdmi_in.start()\n",
    "\n",
    "base.video.hdmi_out.configure(mode, rgba)\n",
    "base.video.hdmi_out.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoMode: width=1280 height=720 bpp=32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.video.hdmi_in.mode # Check input mode; Should be 1280x 720"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This should turn on the monitor but nothing will be displayed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "filter2d = base.video.filter2d_0\n",
    "\n",
    "coeffs = np.frombuffer(filter2d.mmio.mem, np.int16, 96, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The arguments to `np.frombuffer` are the buffer object, the type we want, the number of elements and the offset in bytes. 96 is chosen because that's the number of 16-bit integers that can fit into the range 0x40 to 0xFF and 64 is the offset of the coeffs1 array.\n",
    "\n",
    "Now we have the master array we can get the slices for each particular set of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "c1 = coeffs[0:25].reshape((5,5))\n",
    "c2 = coeffs[32:57].reshape((5,5))\n",
    "c3 = coeffs[64:89].reshape((5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note that while we have specified the types here as a 16-bit integer the type used by the hardware is a 16-bit fixed-point number so we need multiply the value of the coefficients by 256 when writing them to the hardware. Finally we can make our filter pass through the signal intact and (hopefully) see something on the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Make sure something is being displayed on HDMI out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "base.video.hdmi_in.tie(base.video.hdmi_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Some options for filters: https://en.wikipedia.org/wiki/Kernel_%28image_processing%29\n",
    "\n",
    "default_mask = np.frombuffer(filter2d.mmio.mem, np.int16, 96, 64)\n",
    "default_mask = [[0, 0,  0, 0, 0],\n",
    "                [0, 0,  0, 0, 0],\n",
    "                [0, 0,256, 0, 0],\n",
    "                [0, 0,  0, 0, 0],\n",
    "                [0, 0,  0, 0, 0]]\n",
    "\n",
    "blank_mask = np.frombuffer(filter2d.mmio.mem, np.int16, 96, 64)\n",
    "blank_mask = [[0, 0,  0, 0, 0],\n",
    "                [0, 0,  0, 0, 0],\n",
    "                [0, 0, 0, 0, 0],\n",
    "                [0, 0,  0, 0, 0],\n",
    "                [0, 0,  0, 0, 0]]\n",
    "\n",
    "sobel_mask = np.frombuffer(filter2d.mmio.mem, np.int16, 96, 64)\n",
    "sobel_mask = [[0,0,  1,0,0],\n",
    "              [0,1,  2,1,0],\n",
    "              [1,2,-16,2,1],\n",
    "              [0,1,  2,1,0],\n",
    "              [0,0,  1,0,0]]\n",
    "sobel_mask = 256*np.array(sobel_mask)\n",
    "\n",
    "enhance_mask = np.frombuffer(filter2d.mmio.mem, np.int16, 96, 64)\n",
    "enhance_mask = [[0, 0,  5, 0, 0],\n",
    "                [0, 5,  9, 5, 0],\n",
    "                [5, 9,256, 9, 5],\n",
    "                [0, 5,  9, 5, 0],\n",
    "                [0, 0,  5, 0, 0]]\n",
    "\n",
    "sharpen_mask = np.frombuffer(filter2d.mmio.mem, np.int16, 96, 64)\n",
    "sharpen_mask = [[0, 0,  0, 0, 0],\n",
    "                [0, 0, -1, 0, 0],\n",
    "                [0,-1,  5,-1, 0],\n",
    "                [0, 0, -1, 0, 0],\n",
    "                [0, 0,  0, 0, 0]]\n",
    "sharpen_mask = 256*np.array(sharpen_mask)\n",
    "\n",
    "gaussian_blur_mask = np.frombuffer(filter2d.mmio.mem, np.int16, 96, 64)\n",
    "gaussian_blur_mask = [[1, 4,  6, 4, 1],\n",
    "                      [4,16, 24,16, 4],\n",
    "                      [6,24, 36,24, 6],\n",
    "                      [4,16, 24,16, 4],\n",
    "                      [1, 4,  6, 4, 1]]\n",
    "\n",
    "c1[:] = default_mask[:]\n",
    "c2[:] = default_mask[:]\n",
    "c3[:] = default_mask[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Video filter\n",
    "\n",
    "Change the mask in the cell below to change the function for each button.\n",
    "\n",
    "1. Selects Default (pass through)\n",
    "2. Selects edge detection\n",
    "3. Selects a blur filter\n",
    "4. Cycles through Red/Blue/Green channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "count = 0\n",
    "while (base.switches[0].read()==0):\n",
    "    if (base.buttons[0].read()==1):\n",
    "        c1[:] = default_mask[:]\n",
    "        c2[:] = default_mask[:]\n",
    "        c3[:] = default_mask[:]\n",
    "        count = 0\n",
    "        time.sleep(.1)\n",
    "    elif (base.buttons[1].read()==1):\n",
    "        c1[:] = sobel_mask[:]\n",
    "        c2[:] = sobel_mask[:]\n",
    "        c3[:] = sobel_mask[:]\n",
    "        count = 0\n",
    "        time.sleep(.1)\n",
    "    elif (base.buttons[2].read()==1):\n",
    "        c1[:] = gaussian_blur_mask[:]\n",
    "        c2[:] = gaussian_blur_mask[:]\n",
    "        c3[:] = gaussian_blur_mask[:]\n",
    "        count = 0\n",
    "        time.sleep(.1)\n",
    "    elif (base.buttons[3].read()==1):\n",
    "        if count is 0:\n",
    "            c1[:] = default_mask[:]\n",
    "            c2[:] = blank_mask[:]\n",
    "            c3[:] = blank_mask[:]\n",
    "            count += 1\n",
    "        elif count is 1:\n",
    "            c1[:] = blank_mask[:]\n",
    "            c2[:] = blank_mask[:]\n",
    "            c3[:] = default_mask[:]\n",
    "            count += 1\n",
    "        elif count is 2:\n",
    "            c1[:] = blank_mask[:]\n",
    "            c2[:] = default_mask[:]\n",
    "            c3[:] = blank_mask[:]\n",
    "            count = 0\n",
    "        time.sleep(0.5)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
